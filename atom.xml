<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ItchyHiker</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://itchyhiker.com/"/>
  <updated>2018-03-30T14:56:21.003Z</updated>
  <id>https://itchyhiker.com/</id>
  
  <author>
    <name>Vincent</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>First Test Demo(CS231n Lecture *)</title>
    <link href="https://itchyhiker.com/First-Test-Demo/"/>
    <id>https://itchyhiker.com/First-Test-Demo/</id>
    <published>2018-03-30T14:44:00.000Z</published>
    <updated>2018-03-30T14:56:21.003Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><p>##So far this week</p><ul><li>Edge detection</li><li>RANSAC</li><li>SIFT</li><li>K-Means</li><li>Linear classifier</li><li>Mean-shift</li><li>PCA/Eigenfaces</li><li><p>Image features<br>##Current Research<br><img src="./1512948999177.png" alt="Alt text"></p></li><li><p>Learning hierarchical representations from data</p></li><li>End-to-end learning: raw inputs to predictions</li><li>can use a small set of simple tools to solve many problems</li><li>has led to rapid progress on many problems</li><li>Inspired by the brain(very loosely!)</li></ul><p>##Deep learning for different problems</p><h3 id="vision-tasks"><a href="#vision-tasks" class="headerlink" title="vision tasks"></a>vision tasks</h3><ul><li>visual recognition<br><img src="./1512949466324.png" alt="Alt text"><br><img src="./1512949506054.png" alt="Alt text"></li><li>object detection: what and where<br><img src="./1512949600151.png" alt="Alt text"></li><li>object segmentation</li><li>image caption</li><li>visual question answering</li><li>super resolution</li><li>image retrieval</li><li>style transfer<h3 id="outside-vision-tasks"><a href="#outside-vision-tasks" class="headerlink" title="outside vision tasks"></a>outside vision tasks</h3></li><li>Machine Translation</li><li>Text Synthesis</li><li>Speech Recognition</li><li>Speech Synthesis</li></ul><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>Data-driven approach:</p><ol><li>collect a dataset of images and labels</li><li>use machine learning to train an image calssifier</li><li>evaluate the classifier on a withheld set of test images<br><img src="./1512950593146.png" alt="Alt text"><br>feature learning<br>what is feature learning?[^1]<br><img src="./1512950762827.png" alt="Alt text"><br>deep learning<br><img src="./1512950785202.png" alt="Alt text"></li></ol><h2 id="Supervised-learning"><a href="#Supervised-learning" class="headerlink" title="Supervised learning"></a>Supervised learning</h2><p><img src="./1512951055407.png" alt="Alt text"></p><h3 id="linear-regression"><a href="#linear-regression" class="headerlink" title="linear regression"></a>linear regression</h3><p><img src="./1512956741961.png" alt="Alt text"></p><p>###neural network<br><img src="./1512956783266.png" alt="Alt text"><br>neural networks with many layers<br><img src="./1512956866393.png" alt="Alt text"></p><p>[^1]:<br>In Machine Learning, feature learning or representation learningis a set of techniques that learn a feature: a transformation of raw data input to a representation that can be effectively exploited in machine learning tasks. This obviates manual feature engineering, which is otherwise necessary, and allows a machine to both learn at a specific task (using the features) and learn the features themselves.<br>Feature learning is motivated by the fact that machine learning tasks such as classification often require input that is mathematically and computationally convenient to process. However, real-world data such as images, video, and sensor measurement is usually complex, redundant, and highly variable. Thus, it is necessary to discover useful features or representations from raw data. Traditional hand-crafted features often require expensive human labor and often rely on expert knowledge. Also, they normally do not generalize well. This motivates the design of efficient feature learning techniques, to automate and generalize this.<br>Feature learning can be divided into two categories: supervised and unsupervised feature learning, analogous to these categories in machine learning generally.<br>In supervised feature learning, features are learned with labeled input data. Examples include Supervised Neural Networks, Multilayer Perceptron, and (supervised) dictionary Learning.<br>In unsupervised feature learning, features are learned with unlabeled input data. Examples include dictionary learning, independent component analysis, autoencoders, and various forms of clustering.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;##So far this week&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Edge detection&lt;/li&gt;
&lt;li&gt;RANSAC&lt;/li&gt;
&lt;li&gt;SIFT&lt;/li&gt;
&lt;li&gt;K-Means&lt;/li&gt;
&lt;li&gt;Linear classifier&lt;/li
      
    
    </summary>
    
    
      <category term="-DeepLearning -ComputerVision" scheme="https://itchyhiker.com/tags/DeepLearning-ComputerVision/"/>
    
  </entry>
  
  <entry>
    <title>New Day of ItchyHiker</title>
    <link href="https://itchyhiker.com/New-Day-of-ItchyHiker/"/>
    <id>https://itchyhiker.com/New-Day-of-ItchyHiker/</id>
    <published>2018-03-30T11:06:54.000Z</published>
    <updated>2018-03-30T14:04:49.615Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Hello-world"><a href="#Hello-world" class="headerlink" title="Hello world!"></a>Hello world!</h1><p>2018-03-30-17:00<br><a id="more"></a></p><h2 id="HitchyHiker的起源"><a href="#HitchyHiker的起源" class="headerlink" title="HitchyHiker的起源"></a>HitchyHiker的起源</h2>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Hello-world&quot;&gt;&lt;a href=&quot;#Hello-world&quot; class=&quot;headerlink&quot; title=&quot;Hello world!&quot;&gt;&lt;/a&gt;Hello world!&lt;/h1&gt;&lt;p&gt;2018-03-30-17:00&lt;br&gt;
    
    </summary>
    
    
      <category term="Diary" scheme="https://itchyhiker.com/tags/Diary/"/>
    
  </entry>
  
</feed>
